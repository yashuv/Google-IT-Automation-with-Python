# Crashing Programs
In this module, you’ll get introduced to the age old question, “Why has my program crashed?” You’ll learn how to troubleshoot system crashes and application crashes, what tools can be used to help identify the cause of the crash, and what log files to look at in order to find what might have gone wrong. Next, you’ll dive into investigating why code crashes, and what you can do to prevent that from happening. Then, you’ll explore what happens when an unhandled error occurs and throws an exception. You’ll learn about the printf debugging technique, which will help you identify these errors and exceptions. Finally, you’ll explore the concept of handling crashes and incidents at a much larger scale. You’ll delve into a scenario where a large eCommerce site will throw an error 20% of the time. Once that issue has been fixed, you’ll understand the importance of communication and documentation during these incidents, and how writing a post mortem can prevent issues from happening again.

## Learning Objectives
* Understand the difference between system and application crashes
* Utilize skills in debugging and log reading to identify these crashes
* Understand the different types of code crashes and be able to address invalid memory errors
* Utilize techniques, like printf debugging, to troubleshoot and resolve unhandled errors and exceptions
* Understand how communication and documentation during an outage or error is critical
* Understand what a postmortem is and what should be included in one

### Intro to Module 3: Crashing Programs
In the last module, we learned about a bunch of things that can make our computer, our code, or our systems run slow. We looked into the root causes and the possible remedies that might improve performance. You're sure not suffering from slowness, you've already zoomed through the first half of the course. Great job. In this module, we'll look at another area of IT that often keeps us busy. The many things that can cause programs to crash unexpectedly. If you've used computers, you've seen software crash at one time or another. A program terminates unexpectedly, a device reboots for no apparent reason, the operating system hangs and we lose all our unsaved work, programs that terminate with uncaught exceptions, systems that fail to update to the latest version, jobs that silently die. Not long ago, I had to debug a program that was crashing every few days. This program parsed logs to generate alerts when it found suspicious events. When the task crashed, everything being processed was dropped. The task was then restarted and the log files reprocessed. So while no data was actually loss, the reoccurring crashes were increasing the average time to process the data. To fix this, I first follow the code to understand what it did. That led me to figure out the problem. The program was starting a bunch of threads but never closing them, so it eventually ran out of memory and crashed. I was then able to fix it by making sure all threads got cleaned up once they've completed their task. Generally, the cause of these crashes is that the software ran into an unexpected situation, a state that the developers didn't anticipate. Because these are unexpected situations, they can be triggered by very broad range of things. It could be a hardware problem, like a broken ramjet that causes a program to get invalid data when trying to access the memory. There could be a bug in some part of the code, which does an unsupported operation, like trying to read an element from an empty list. It could be an issue in the overall system, like if a program expects a certain library to be present or a certain directory to exist, but they don't or there could be a problem with the input provided by the user. Like if we ask the user to enter a number and they enter a string instead. The list goes on. There are a ton of things that can cause a crash. Instead of knowing all of them, we need to learn to reduce the scope of the problem so that we can get to the bottom of it. In the next few videos, we'll learn a bunch of different techniques that we can use to understand the root causes and how to fix them, or at least lessen the damage when fixing is not possible. We'll first look at how we can understand the problem. We'll then check out what we can do when we don't have access to change the program's code, and what we can do when we do have access to the source code, even if it's not our own code. Finally, we'll also look at what to do when the problem isn't just one computer crashing, but a larger incident affecting complex systems. We'll also dive into how to document a problem and it's solutions, and how to learn from our mistakes by writing postmortems. As usual, we'll put all this knowledge into action by solving real-world problems. You'll have the opportunity to try fixing a complex crashing problem by the end of the module. Let's get going.

### Systems That Crash
In this section, we're going to talk about system crashes.

There are a ton of different reasons why applications crash. When we come across a program that terminates unexpectedly, we go through our usual cycle of gathering information about the crash, digging in until we find the root cause, and then applying the right fix. Say for example that a user asks for your help with a problem on their computer. When you ask for details, the user tells you that the internal billing application crashed while they were trying to generate an invoice for a customer. Now, this could be caused by lots of different things. So what you need to do is reduce the scope of the problem, and remember, you want to start with the actions that are easier and faster to check. As a first step, you tried looking at the logs to see if there's any error that may point to what's happening, but you only find an error saying application terminated and no useful information. So you check if the user can reproduce the problem by doing this same action on a different computer. You ask the user to try this out, and it turns out on a different machine that can generate the invoice just fine. So that means that the problem just has to do with the installation or configuration on that specific computer. Great news. You've already reduced the scope to something machine-specific. Another thing that you might want to check is if this happens reliably. Do all invoice generations fail? Is it confined to one specific product or customer? For this example, let's say that when you ask the user to try generating other invoices, it works just fine even for the same customer. Okay, you think maybe this problem was with a specific order for that specific customer on that specific computer. That's rather suspicious, but not so fast. The user tells you that after creating all the invoices for the day, they tried to generate a report, and the application crashed again. But then it worked the next time. You double-check with other users and find out the application isn't crashing when they use it. So what does this mean? The application seems to be crashing randomly but only on that computer. To further reduce the scope, you'll want to know if it's just that application or the whole system. To check this out, you can try moving away the local configuration for the program and using the default configuration instead, or maybe even reinstalling the application. You might also ask the user if they've seen crashes on any other application. For this example, let's say that reinstalling the application and running it with the default configuration still leads to random crashes. I'm impressed to remember, the user tells you that their web browser also crashed last week when they were using the internal webmail. At this point, the information points to a problem in the overall system, either the hardware or the OS installation. If you have a spare computer available, it might make sense to give one to the user at this point so that they can go back to work while you try to figure out the root cause of the problem. What can you do to further reduce the scope? By now, there's a high likelihood if the problem being hardware related. So one thing you could do is try taking the hard drive out of the computer and putting it into a different computer. This works best when you already have a spare case that you know works well so that you can use it for tests like these. That way you can quickly check if it's a problem with the data and the drive or the rest of the computer. Let's say that after putting the hard drive in the other computer, the applications run without unexpected crashes. This means that some hardware component is at fault. The next step is to find out which one. Given the random crashes, one thing to check would be the RAM. Memory chips deteriorate over time. When they do, the computer might write data to some part of the memory and then get a totally different value when trying to read it back. To check the health of our RAM, we can use the memtest 86 tool to look for errors. We run this tool on boot instead of the normal operating system so that it can access all of the available memory and verify if the data written to memory is the same when it tries to read it back. If the RAM is fine, you can check if the computer's overheating by looking at the sensor data provided by the OS. If that's not the case, check if there's a problem with external devices like a graphics card or sound card. You can do this by disconnecting or replacing the devices present in the computer and checking if the crashes still occur. So what can you do if when putting the hard drive in a separate computer, you still get the strange caches? This means the problem is in the drive itself or the OS installation. As with RAM, our hard drives age. At some point, the data that the computer reads stops matching what was originally stored. Each OS ships its own battery of hard drive checking tools, and you should familiarize yourself with ones in the OS you're working with. You'll want to look at the output of the tools that check the disk for bad sectors, and you'll also want to use these S.M.A.R.T tools which can help detect errors and even try to anticipate problems before they affect the computer's performance. What can you do with the hard-drive turns out to be fine? You'd need to look into the possible OS issues, but before doing that, ask yourself, is it worth it? Looking to what's wrong with the installation can take a lot of valuable time. If the installation is easy to replicate, then just reinstalling the OS might be faster and simpler than looking into why it broke. Alright, so that's a glimpse of how you can try to diagnose a system that's unstable and behaving in weird ways. But often, you'll be dealing with a specific application that's misbehaving. In this case, it's almost certainly above in the application's code that's not taking into account a situation that, though unexpected, can sometimes occur. Up next, we'll check out what you can do when that happens.

### Understanding Crashing Applications
 When an application crashes and we don't know why we'll want to look for logs that might relate to the failure. To look at logs on Linux will open the system log files and VAR log or the user log files and dot accession errors file. On Mac OS we generally use the console app to look at logs and the event Viewer on Windows. So what kind of data should you look for in these logs most logs have a date and time for each line locked knowing when the application crashed you can look for a log line around that time. And try to find an error message related to the application that crashed. Sometimes the errors will be self-explanatory like permission denied no such file or directory connection refused. Sometimes it will be a cryptic message and you have no idea what it means. Ever we have an error message no matter how weird it seems we can search for it online to try to figure out its meaning. If we're lucky, we might find the official documentation of what that error means and what we can do about it. But even if that's not available, will usually come across posts by others who have tackled a similar error and this additional information can help us understand what's going on. If there are no errors or the errors aren't useful we can try to find out more info by enabling sling debug logging. Many applications generate a lot more output when debugging logging is enabled. We might need to enable it from a setting in the applications configuration file or a command line parameter to pass when running the application manually. By enabling this extra logging information, we can get a better idea of what's actually causing the problem. And what do we need to do if there are no logs or error messages at all. In that case we need to use tools that let us see what going on inside the program. We call that a few are ready. On Linux we use S Trace to see what system calls a programs doing. The equivalent tool is called de trois on Mac OS process monitor is a Windows tool that can also take a peek inside what's going on inside a process on Windows?

By tracing which system calls a program is doing we can see what files and directories it's trying open what network connections it's trying to make and what information it's trying to read or write. This can give us a better idea of what caused the actual problem. We could find that the problem is caused by a resource not being present that the program expects to be present. Like we saw with the missing directory example in the earlier module or we could find that the program tries to interact with the graphics interface and there isn't any because it's a service running on a server. Or the program tries to open a file but the user running the software doesn't have the necessary permissions. If the application used to work fine and recently started crashing. It's useful to look into what changed in between. The first thing is to check if the issue is caused by a new version of the application itself. Maybe there's a bug in the new version that causes the crash or maybe the way that we're using the application is no longer supported. But that's not the only possible change that could trigger crashes. It could also be that a library or service used by our application changed and they no longer work well together or it could be that there was a configuration change in the overall environment. Like if the user isn't in a specific group anymore or if the files that the application used are in a different location. When trying to figure out what changed logs can also be a useful source of information. In the system log we can check which programs and libraries were recently updated checking for configuration changes might be harder depending on how you manage that configuration. If the settings are managed through a configuration management system and the values are stored in a Version Control System. Then you might be able to look at the history of changes and figure out which one triggered the failure. We call that a few times already how important it is to have a reproduction case for a problem that we're trying to solve. When we're trying to debug an application that crashes finding a reproduction case can help us both understand what's causing the crash and figure out what we can do to fix it. So it's valuable to spend some time figuring out the state that triggers the crash. This includes the overall system environment the specific application configuration the inputs to the application the outputs generated by the application the resources that uses and the services it communicates with. When trying create the reproduction case it might be useful to start from a clean slate and slowly put the pieces in place until the crash triggers. This might include trying out the application with the default configuration instead of the local one or on a freshly installed computer instead of the computer where it's crashing. And remember we want to make the reproduction case as small as possible this lets us better understand the problem and also quickly check if its present or not when we attempt to fix it. And even if we end up unable to fix the issue having a small and simple reproduction case is extremely helpful in reporting a bug to the program's developers. So to sum this up to find the root cause of a crashing application will want to look at all available logs figure out what changed trace the system or library calls the program makes and create the smallest possible reproduction case.

After doing all of this, we should have some idea of what the root cause of the issue is and maybe even how to fix it.

The strategy for fixing problems will depend on whether we can fix the code or not. In our next section, we'll check out what you can do when you can't fix the program and need to work around the issue. And in later sections, we'll deep dive into strategies for fixing faulty code.

### What to do when you can't fix the program?
One of the great things about working in IT is that we can tell the computer what to do and it will follow our orders. When dealing with unexpected behavior in the software written by other people though, we might not always be so lucky. It could be that we're dealing with proprietary software and the source code isn't available at all, or we might have access to the source code but it's written in a language that we don't understand and so we can't change it. No matter the reason, what can you do if you need to fix an application that crashes and you can't change the code. You'll need to figure out a way of working around the problem and avoiding the crash. The actual workaround will depend on what the issue is that you're trying to solve. Let's do a rundown of some of the available options. Say you figured out that the issue was caused by a specific data input that makes the application crash. The crashes only happen when the input isn't in the format the code expects. Some of your systems generate data in XML format which used to work fine with the previous version of the software but the new version now requires all data to be in a YAML format. In this case you can write a script that pre-processes the data and make sure that it's in the format that the program expects. Similarly if the problem is caused by an external service that the application uses and that's no longer compatible, we could write a service to act as a proxy and make sure that both sides see the requests and responses they expect. This type of compatibility layer is called a Wrapper. A Wrapper is a function or program that provides a compatibility layer between two functions or programs so they can work well together. Using Wrappers is a pretty common technique when the expected output and input formats don't match. So if you're faced with some sort of compatibility problem don't be afraid to write a Wrapper to work around it. Another possibility you might need to look at is if the overall system environment is it working well with the application. In this case, you might want to check what environment the applications developers recommend and then modify your systems to match that. This could be running the same version of the operating system using the same version of the dynamic libraries or interacting with the same back end services. Say the application was developed and tested on Windows 7, if you run into problems while trying to run it under Windows 10, you might want to use Windows 7 instead or if the application was developed and tested for Ubuntu and you're having trouble running it under Fedora, you might want to try running it on Ubuntu instead, and what can you do if you can't make the environment match? This could happen, for example, if there's another application that requires a different version of the same library or you can't change a certain configuration setting because it's required to access a different service. In this case, you might want to consider running the application inside a virtual machine or maybe a container. These are two different things but we won't go into details of how they are different here. All you need to know right now is they both let you run the affected application in its own environment without interfering with the rest of the system. This is what we need if we want the environment to be different than the one other Applications are using on the same computer. Sometimes we can't find a way to stop an application from crashing but we can make sure that if it crashes it starts back again. To do this, we can deploy a watchdog. This is a process that checks whether a program is running and when it's not starts the program again. To implement this, we need to write a script that stays running in the background and periodically checks if the other program is running. Whenever the check fails the watchdog will trigger the program to restart. Doing this won't avoid the crash itself. But it will at least ensure that the service is available. This works well for services where availability matters more than running continuously and no matter how you work around the issue, remember to always report the bug to the application developers. As we called out, if you have a good reproduction case for your issue, it makes it easier for the developers to figure out what's wrong and how to fix it. So when you report a bug make sure you include as much information as possible, share good reproduction case and answer the questions that we mentioned earlier on. What were you trying to do? What were the steps you followed? What did you expect to happen? What was the actual outcome? Up next, we'll see how to apply these skills to troubleshoot an application that's crashing.

### Internal Server Error
A colleague has alerted us that a webpage on our Web server isn't working. As we've done before, we need to figure out what this means exactly. We asked our colleague for more details and they told us that the failing webpage is at *site.example.com/blogs*. Let's check out if this is failing for us as well. There it is, the server responded with a *500* error. This error usually means that something on the server side of the application crashed, but we have no idea what. We'll need to investigate to find out more information. Let's connect to the Web server and try to figure out what's up. 
```bash
ssh webserver
```

The first step is looking at logs, as we called out on Linux systems, logs are located in `/var/log`. To do that, we'll use the date command to check the current date.
```bash
date
```
Let's change into that directory and check out if there are any recent logs about our error 
```bash
cd  /var/log/
```
and then the `ls -lt | head` command which sorts the files by the last modified date connecting it to the head command to keep the top 10 lines. We just triggered the error but there doesn't seem to be anything recent in the logs. Just in case, let's check out the last lines insists log using tail.
```bash
tail syslog
```
Nope. Nothing interesting here. We need to figure out how we can get more information, but we don't even know which web surfing software is being used on this computer. But we do know that the Web server is running on `port 80`, *the default web serving port*. How can we find which software is listening on port 80? We can use the `netstat` command which can give us a bunch of information about our network connections depending on the flags we pass. This command accesses a bunch of sockets that are restricted to route the administrator user on Linux. So we'll need to call it with *sudo* which lets us run commands as root, and then we'll pass a bunch of flags netstat. We'll use `-n` to print numerical addresses instead of resolving host names, `l` to only check out the sockets that are listening for connection, and `p` to print the process ID and name to which each socket belongs. Since we only care about port 80, we'll connect the output to a `grep` command checking for :80.
```bash
sudo netstat -nlp | grep :80
```
Great, we got new information. We see that the process listening in port 80 is called *"nginx"*, one of the popular web serving applications out there. We now want to check out the configuration for our site. Configuration files on Linux are stored in the *etc directory*. So let's look at `etc/nginx`.
```bash
ls -l /etc/nginx/
```
There's a bunch of files here. Lots of different configuration options that you can set in the Web server. We're looking for the configuration related to a specific site. So let's look at `etc/nginx/sites-enabled`.
```bash
ls -l /etc/nginx/sites-enabled/
```
There are two files here one for the default site and one for the site.example.com site that's the one we want. Let's open it with the vim editor.
```bash
vim /etc/nginx/sites-enabled/site.example.com.conf
```
There's not a lot here, but at the bottom we see that it says uwsgi_pass, and then the local host address followed by a different port number. It seems that this website isn't being served directly from nginx, instead, the software is passing the control of the connections to uWSGI which is a common solution used to connect a Web server to programs that generate dynamic pages. So let's see if we can find the configuration for that one. We'll *exit* vim with a *:q* and then see if there's anything interesting in `etc/uwsgi`. 
```bash
ls -l /etc/uwsgi/
```
Here we only see two directories, *apps-available* and *apps-enabled*. Let's say it's an apps-enabled.
```bash
ls -l /etc/uwsgi/apps-enabled/
```
Cool. We found the uWSGI configuration for our site. Let's check it out.
```bash
vi /etc/uwsgi/apps-enabled/site.example.com.ini
```
Nice. This file has a lot more information. We see that the main directory for the application is `srv/site.example.com` that the applications run as the www-data User and Group, that it's running a Python three script called prod.py that the log is stored in var/log/site.log and a bunch of other things. All right. Let's use this extra information and see if we can find out what's that. Let's exit with :q once more and then check out that log file. Weird, the log file has a size of zero, that doesn't seem right. Let's see if we can find out anything else by looking at the Python script that's executed by uwsgi srv/site.example.com/prod.py.
```bash
vi /srv/site.example.com/prod.py
```
There's a few different webpages configured in this file. It uses bottle which is a Python module to generate dynamic web pages. At the bottom, we see the configuration for the logs page that's currently failing. Hopefully, a colleague left a comment saying that we can get debugging information by uncommenting the line that calls bottle.debug. That's exactly what we need. To uncomment this line, we need to have write access to the file though, and VI is open in read only mode currently. Let's exit an open again with sudo to be able to modify it.

Okay. We've made the change, let's save it and reload uwsgi as the instructions say. We'll do this by running `sudo service uwsgi reload`.

We've added debugging information. Hopefully, that will tell us why the pages failing. Let's reload the website and see what happens.

Great news, this time we see a trace back of the error and we see that the issue is that the application is getting a permission denied error when trying to open var/log/site.log. Remember that we thought it was weird that the file was empty, it seems that it's somehow broken. Let's look at it again, this time let's check if there are any other files that start with site.
```bash
ls -l site*
```
So there's a site.log file and a site.log.1 file. That's pretty common when using log rotate to rotate the logs and avoid them getting too big. But there's something else afoot here. See how one file belongs to the root user and the other belongs to the www-data user. If you look at the permissions of the file, you might notice that they are set to allow the owner to write them and the owner and the group to read them, but the rest of the users can't access them. We saw earlier that the application is running with the www-data user. So if site.log belongs to the root user, the application won't be able to either read or write to this log file. Ding-ding-ding. seems like we found the root cause of our issue. Let's change the owner of the site.log file to fix the immediate problem.
```bash
sudo chown www-data.ww-data site.log
```
Let's try reloading our page now.

Yes, it works. The log is empty now because the application have not been able to write to it. But if we keep reloading, we'll see how it populates with our entries.

All right. We've fixed the immediate problem our Web pages working once again, but we still need to take care of the long-term remediation. Why was the ownership of the file wrong? We suspect that there might be something wrong with the log rotate configuration but we'd need to keep looking to find out what's up with that. In this section, we looked into how we can figure out what's up with an application that's failing. We checked out a bunch of different tools and ideas that can help us understand what's going on and get more information until we can find the root cause. I hope we're starting to see how these lessons provide valuable tools for diagnosing and solving issues that will for sure occur at your job. Up next, we have a reading with some links to learn more about different things that can make your computer crash.

### Resources for Understanding Crashes
There's a ton of different reasons why a computer might crash. This <a href="https://www.scientificamerican.com/article/why-do-computers-crash/">Scientific American article</a> discusses many of the possible reasons, including hardware problems and issues with the overall operating system or the applications on top. 

On Linux or MacOS, the worst kind of crash is called a Kernel Panic. On Windows, it's known as the <a href="https://en.wikipedia.org/wiki/Blue_Screen_of_Death">Blue Screen of Death</a>. These are situations where the computer completely stops responding and only a reboot can make it work again. They don't happen often, but it's good to understand what they mean: the whole OS encountered an error and it can't recover.

We called out that reading logs is super important. You should know how to read logs on the operating system that you're using. Here are some resources for this:

* <a href="https://www.digitalmastersmag.com/magazine/tip-of-the-day-how-to-find-crash-logs-on-windows-10/">How to find logs on Windows 10</a> (Digital Masters Magazine)

* <a href="https://www.howtogeek.com/356942/how-to-view-the-system-log-on-a-mac/">How to view the System Log on a Mac</a> (How-to Geek)

* <a href="https://www.fosslinux.com/8984/how-to-check-system-logs-on-linux-complete-usage-guide.htm">How to check system logs on Linux</a> (FOSS Linux) 

You also need to be familiar with the tools available in your OS to diagnose problems. These are the tools we called out, but you don't need to limit yourself to them:

* <a href="https://docs.microsoft.com/en-us/sysinternals/downloads/procmon">Process Monitor</a> for Windows (Microsoft)

* <a href="https://www.howtoforge.com/linux-strace-command/">Linux strace command tutorial for beginners</a> (HowtoForge)  

* <a href="https://etcnotes.com/posts/system-call/">How to trace your system calls on Mac OS</a> (/etc/notes)

## Code that Crashes:
### Accessing Invalid Memory
In our earlier sections, we looked into a bunch of different things that can make software crash and what we can do about them when we can't fix the code. If we're able to make the application behave correctly though, we'll have a lot more options for dealing with the crash. Of course to apply these fixes, we'll need to understand why the crash is even happening. One common reason a program crashes is it's trying to access invalid memory. To understand what this means, let's quickly explain how using the memory works on modern operating systems. Each process running on our computer asks the operating system for a chunk of memory. This is the memory used to store values and do operations on them during the program's execution. The OS keeps a mapping table of which process is assigned which portion of the memory. Processes aren't allowed to read or write outside of the portions of memory they were assigned. So accessing invalid memory means that the process tried to access a portion of the system's memory that wasn't assigned to it. Now, how does this even happen? During normal working conditions, applications will request a portion of the memory and then use the space at the OS assigned to them. But programming errors might lead to a process trying to read or write to a memory address outside of the valid range. When this happens, the OS will raise an error like segmentation fault or general protection fault. What kind of programming error is this? It typically happens with low-level languages like C or C++ where the programmer needs to take care of requesting the memory that the program is going to use and then giving that memory back once it's not needed anymore. In these languages, the variables that store memory addresses are called pointers. They're just like any other variable and code that can be modified as needed. So if a pointer is set to a value outside of the valid memory range for that process, it will point to invalid memory. If the code then tries to access the memory the pointer points to, the application will crash. Common programming errors that lead to segmentation faults or segfaults include forgetting to initialize a variable, trying to access a list element outside of the valid range, trying to use a portion of memory after having given it back, and trying to write more data than the requested portion of memory can hold. So what can you do if you have a program that's said vaulting? The best way to understand what's going on is to attach a debugger to the faulty program. This way when the program crashes, you'll get information about the function where the fault happened. You'll know the parameters that the function received and find out the address that was invalid. That might already be enough to understand the problem. Maybe a certain variable is being initialized to late or the code is trying to read too many items on a list. If that's not enough, the debugger can give you a lot more detail on what the application is doing and why the memories invalid. For this to be possible, we'll need our program to be compiled with debugging symbols. This means that on top of the information that the computer uses to execute the program, the executable binary needs to include extra information needed for debugging, like the names of the variables and functions being used. These symbols are usually stripped away from the binaries that we run to make them smaller. So we'll need to either recompile the binary to include the symbols, or download the debugging symbols from the provider of the software if they're available. Linux distributions like Debian or Ubuntu ships separate packages with the debugging symbols for all the packages in the distribution. So to debug and application that's segfaulting, we download the debugging symbols for that application. Attach a debugger to it, and see where the fault occurs. When doing this, we might find that the crash happens inside a call to a library function. This is separate from the application itself, so we need to install the debugging symbols for that library. We might need to repeat this cycle a few times before we can identify the portion of the code that's buggy. Microsoft compilers can also generate debugging symbols in a separate PDB file. Some Windows software providers let users download the PDP files that correspond to their binaries to let them properly debug failures. One of the trickiest things about this invalid memory business is that we're usually dealing with undefined behavior. This means that the code is doing something that's not valid in the programming language. The actual outcome will depend on the compiler used, how the operating system assigns memory to processes, and even the version of the libraries in use. A program that runs fine on a computer running Windows trigger a segfault on a computer running Linux and vice versa. When trying to understand problems related to handling invalid memory, valgrind can help us a lot. Valgrind is a very powerful tool that can tell us if the code is doing any invalid operations no matter if it crashes are not. Valgrind lets us know if the code is accessing variables before initializing them. If the code is failing to free some of the memory requested, if the pointers are pointing to an invalid memory address, and a ton more things. Valgrind is available on Linux and Mac OS, and Dr. Memory is a similar tool that can be used on both Windows and Linux. So all of that said, what do we do when we finally discover the cause of the segfaults? You'll want to either change the code yourself or get the developers to fix the problem in the next version. This might sound scary if you've never programmed in the language used by the application. But when you know what's wrong with the code, it's usually not that hard to figure out how to fix it. If a variable is initialized too late, fixing the problem can be as easy as moving the initialization to the right part of the code, or if a loop is accessing an item outside of the length of the list, you might solve the issue by checking that there aren't more iterations than needed. Throughout this program, we've been teaching you these concepts so you can apply them to any piece of code no matter which language the program is using. So don't be afraid to put this into practice. You've got the skills for it. If the program is part of an open source project, you might find that someone else has already done the work, and so you can apply a patch available online. If there's no patch and you can't say you're the bug out yourself, you can always get in touch with the developers and ask a fake and fix the issue and create the necessary patch. In high-level languages like Python, the interpreter will almost certainly catch these problems itself. It will then throw an exception instead of letting the invalid memory access reach the operating system. But still those exceptions can be pretty annoying. We'll talk about those in our next section.

### Unhandled Errors and Exceptions
In our last section, we talked a lot about what happens when a program tries to access invalid memory. Correctly handling memory is a hard problem, and that's why there's a bunch of different programming languages like Python, Java, or Ruby that do it for us. But that doesn't mean programs written in these languages can't trigger weird problems. In these languages, when a program comes across an unexpected condition that isn't correctly handled in the code, it will trigger errors or exceptions. In Python, for example, we could get an index error if we tried to access an element after the end of a list. We might get a type error or an attribute error if we try to take an action on a variable that wasn't properly initialized or division by zero error if we tried to well, divide by zero. When the code generates one of these errors without handling it properly, the program will finish unexpectedly. In general, unhandled errors happen because the codes making wrong assumptions maybe the program's trying to access a resource that's not present or the code assumes that the user will enter a value but the user entered and empty string instead. Or maybe the application is trying to convert a value from one format to another and the value doesn't match the initial expectations. When these failures happen, the interpreter that's running the program will print the type of error, the line that caused the failure, and the traceback. The traceback shows the lines of the different functions that were being executed when the problem happened. In lots of cases, the error message and traceback info already gives us enough to understand what's going on, and we can move on to solving the problem. But sadly, that's not always the case. The fact that a piece of code crashes on one function doesn't mean that the error is necessarily in that function. It's possible, for example, that the problem was caused by a function called earlier which set a variable to a bad value. So the function where the code crashes is just accessing that variable. So when the error message isn't enough, we'll need to debug the code to find out where things are going wrong. For that, we can use the debugging tools available for the application's language. For a Python, program we can use the BDB interactive debugger which lets us do all the typical debugging actions like executing lines of code one-by-one or looking at how the variables change values. When we're trying to understand what's up with a misbehaving function on top of using debuggers, it's common practice to add statements that print data related to the codes execution. Statements like these could show the contents of variables, the return values of functions or metadata like the length of a list or size of a file. This technique is called print f debugging. The name comes from the print f function used to print messages to the screen in the C programming language. But we can use this technique in all languages, no matter if we use print, puts, or echo to display the text on the screen. Let's take this one step further. When changing code to print messages to the screen, the best approach is to add the messages in a way that can be easily enabled or disabled depending on whether we want the debug info or not. In Python, we can do this using the logging module. This module, lets us set how comprehensive we want our code to be. We can say whether we want to include all debug messages, or only info warning or error messages. Then when printing the message, we specify what type of message we're printing. That way, we can change the debug level with a flag or configuration setting. So you figured out why the unexpected exception was thrown, what do you do next? The solution might be fixing the programming error like making sure variables are initialized before they're used or that the code doesn't try to access elements after the end of a list. Or it could be that certain use cases that hadn't been considered needs to be added to the code. In general, you'll want to make the program more resilient to failures. Instead of crashing unexpectedly, you want the program to inform the user of the problem and tell them what they need to do. For example, say you have an application that crashes with a permission denied error. Rather than the program finishing unexpectedly, you'll want to modify the code to catch that error and tell the user what the permission problem is so they can fix it. For example, unable to write new files and temp, make sure your user has bright permissions on temp. In some cases, it doesn't make sense for our program to even run if certain conditions aren't met. In that case, it's okay for the program to finish when the error is triggered. But again, it should do so in a way that tells the user what to do to fix the problem. For example, if it's critical for an application to connect to a database but the database server isn't responding, it makes sense for the application to finish with an error saying unable to connect to the database server. It also makes sense to include all details of the attempted connection like the host name, the port, or the username used to connect. So to recap, if your program is crashing with an unhandled error, you want to first do some debugging to figure out what's causing the issue. Once you figured it out, you want to make sure that you fix any programming errors and that you catch any conditions that may trigger an error. This way, you can make sure the program doesn't crash and leave your users frustrated. Up next, we'll talk a bit about what you can do when you're trying to fix someone else's code.

### Fixing Someone Else's Code
In our IT jobs, it's pretty common to have to fix problems and code that we didn't write ourselves. It might be because we're working with a program that's open-source or with a program that was developed by someone else inside the company. When this happens, we need to spend some time getting acquainted with the code so that we can understand what's going on. Let's do a rundown of some things that can help us with that. If the code has comments and the functions are well-documented, reading these is a great place to start when trying to figure out what's going on. Remember way back in the course when we first introduced Python, we talked about the importance of developing good habits when we're writing code. Writing good comments is one of those good habits that pays off when trying to understand code written by others and also your past self. Unfortunately, a lot of code doesn't include enough comments, leaving us to try to understand it without enough context. If that's the case, you can improve things by adding comments as you read the code and figure out what it's doing. Writing these comments help you solidify your understanding. If you contribute those comments back to the original developers, you can help anybody else trying to understand the code. Another thing that can help to understand someone else's code is reading the tests associated to the code. Well-written tests can tell us what each function is expected to do. Looking at the existing tests can show us which use cases weren't taken into account. But what if there aren't enough tests? Just like with writing extra comments, writing some tests of your own can help you better see what the code is supposed to do and improve overall quality of the code. This can also be really useful when modifying the original code. To ensure that changes you make, don't break the rest of the functionality. In my job, I need to make changes to code written by other people a lot. I definitely read the comments and sometimes reference the tests too. But in the end, to really understand what's going on, I just have to read through the code. But how do you even start reading through someone else's code? This depends a bit on personal preference and the size of the project. If there are only a couple of 100 lines of code, it's feasible to read all of them. But when the project has thousands or tens of thousands of lines of code, you can't really read the whole thing. You'll need to focus on the functions or modules that are part of the problem that you're trying to fix. One possible approach in this case, would be to start with the function where the error happened, then the function or functions that call it, and so on until you can grasp the contexts that led to the problem. While this is of course much easier if it's in a programming language that you're familiar with, you don't need to be an expert in the language to fix a bug in the program. If you've come across an error and debug the issue well enough to understand what's going on, you might be able to fix the problem even if you've never seen that language before. This is one of those skills that gets better with practice. So it might make sense to you to start practicing before you need to fix a problem in the code. Take a program that you both use and have access to its code and figure out how it does a specific action. Follow the code until you really understand what's going on. For example, you could take the web server software you're using and check out how it parses its configuration files, or take a look at one Python module you like, like Python Request for example, and figure out how it processes the data it receives. Doing this, you can get used to reading code written by others and understanding what it's doing. Another option is to pick an open-source project that you use. Look at the list of open issues and to have a go at fixing an easy one. To do that, you'll need to find your way around the code, understand what it's doing and what to change. By practicing doing this, you'll improve your ability to quickly figure out what the code does and what needs to be changed, while helping improve the project's overall quality. Up next, we'll get some practice fixing issues and a couple of different programs that crash.

### Debugging a Segmentation Fault
Over the past sctions, we've discussed a bunch of different types of crashes. Let's now check out what a segmentation fault looks like in action. We have a simple example program that crashes with a segfault.

When an application crashes like this, it's useful to have a core file of the crash. *Core files* store all the information related to the crash so that we or someone else can debug what's going on. It's like taking a snapshot of the crash when it happens to analyze it later. We need to tell the OS that we want to generate those core files. We do that by running the ulimit command, then using the -c flat for core files, and then saying unlimited to state that we want core files of any size. Once we've done that, we can try executing our example again.

All right, our crashing program has generated a core file. Let's check it out using ls -l.

This file contains all the information of what was going on with the program when it crashed. We can use it to understand why the program crashed by passing it to the GDB debugger. We'll call it `gdb -c core example` to give it a core file and tell it where the executable that crashed is located.

When it starts, GDB shows a bunch of messages including its version, license, and how to get help. It then tells us that the program finished with a segmentation fault. It shows that the crash happened inside the strlen function in a file that's part of the system libraries. The no such file or directory error that we're seeing here means that we don't have the debugging symbols for that system library, but that's okay. We trust the strlen function to work correctly. It's our code that's buggy. Let's look at the full backtrace of the crash by using the `backtrace` command.

The first element in the list is the function where the crash occurred. The second element is the function that called the function and so on. In this case, we see that the strlen function that failed was called by the copy parameters function in our code which was called by the main function. We can use the up command to move to the calling function in the backtrace and check out the line and copy parameters that caused the crash. We see that the faulty line is calling the strlen function, but it's not clear why that would fail. We can get more contexts for the code that failed by calling the list command that shows the lines around the current one.

Here, we see a chunk of C code. If this is the first time you look at C code, it might seem a bit confusing. That's okay. There are some similarities with Python, but also, some things that are pretty different. We see that the faulty line, line 10, is in the body of a for loop. The variable that the for loop uses to iterate is called i. Let's check out the value of i using the print command.

GDB uses the dollar sign followed by a number to give separate identifiers to each result it prints. In this case, the result is one. In other words, when the crash happened, I had the value of one. Since this variable is being used to access an array called argv, let's print the contents of the first element argv 0, and then the second element argv[1].

What are those weird numbers starting with 0x? Those are hexadecimal numbers, and they are used to show addresses in memory where some data is stored. Here, GDB is telling us that the first element in the argv array is a pointer pointing to the./example string. The second element is a pointer to zero also known as a null pointer. Zero is never a valid pointer. It usually signals the end of data structures in C. So our code is trying to access the second element in the array, but the array only has one valid element. In other words, the for loop is doing one iteration to many. This is known as an off-by-one error, and it's a super common error. In this case, the fix is really simple. We need to change the less than or equal sign to be a strictly less than sign so that the iteration stops one element before. In this video, we've got a sneak peek at what it's like debugging C applications that crashed with a segmentation fault. Up next, we'll talk about how we can debug Python applications that crash with an exception.

### Debugging a Python Crash
In our last video, we looked into an application that was crashing with a segmentation fault. That kind of problem is common when dealing with applications written in languages like C or C++. On the flip side, when using languages like Python, we usually need to deal with unexpected exceptions making our program crash. Let's look at one example of that. We have a script that updates the descriptions of some products in our company's database. It's a pretty simple script that takes a CSV file as a parameter, which includes the data that needs to be imported using the product code and description. Our script simply reads through a file and then updates the database. Most of the time it works just fine. But when the file with the new descriptions is generated by one specific user, the program fails with an exception. The user has sent us a file that's failing so that we can try to figure out what's going on. Let's first check out the contents of the file.

Okay, this seems harmless enough. Let's try executing the program.

The program failed with an exception. Let's have a look at this trace back to understand it a bit better. At the bottom, we see the name of the exception. In this case, Key Error and the message in this case, product code, which is the name of the key that's failing. Above that, we see a list of function calls with two lines per function. The first line tells us the Python file that contains the function, the line number, and the name of the function. The second line shows us the contents of that line. This information is similar to the back-trace that we saw in our last video. But the order of the functions is reversed. The function at the bottom, update data, is the one where the exception occurred. Above it, we see that update data was called by main, and on top of that we see that main was called by the line at the module level. So what's going on here? The update data function is trying to access the product code fields in a variable named row. But for some reason this is failing with a Key Error. Frequently, knowing the exception message and the line where the exception happened, is already enough to understand what's going on. But in some cases like this one, that's not enough. It's time to try our hand at using a Python debugger. We'll start the debugger by running pdb3 and then passing the script that we want to run and any parameters that our script needs. In our case, we'll call pdb3 update products.py new products.csv. When we start the debugger it gets positioned at the first line of our script and waits for us to tell it what to do. We could run each of the instructions in the file one by one using the next command. But there's a lot going on here. So we need to go through a lot of lines until we reach the failure. Alternatively, we can tell the debugger to continue the execution until it either finishes or crashes. Let's do that now.

So the program failed in the same way we'd seen before. But now we can use the debugger to get a better idea of why we're getting this pesky key error. Let's print the contents of row.

That's really weird. What are those characters appearing before product code? If we search online for the sequence of characters, will find that they represent the Byte Order Mark or BOM which is used in UTF-16 to tell the difference between a file stored using Little-endian and Big-endian. Our file is in UTF-8 so it doesn't need the BOM. But some programs still include it and this is tripping up our script. So what can we do? Fortunately, others have already faced the same issue and figured out a solution. There is a special value called UTF-8-sig that we can set as the encoding parameter of the open function. Setting this encoding means that Python will get rid of the BOM when files include it and behave as usual when they don't. Let's change the code of our script to use that encoding instead of the default. We'll look for the place where it's opening the file, then add the encoding parameter with UTF-8-sig as the value.

All right. We've made the change. Will they work now? Let's check it out.

Yeah. We've fixed the problem. Our script can now work with users generating files with and without the Byte Order Mark. In the last two videos, we looked briefly at GDB and PDB. We've barely discussed the surface of the many operations that we can do with debuggers. There are ton more advanced debugging features. Like setting breakpoints the letter code run until certain line of code is executed or watch points that letter code run until a variable or expression changes. We can also step through the code instruction by instruction to check when a problem happens and much more. We won't look into any of these advanced techniques here. But as usual, we'll put more information about this in the next reading in case you want to learn more. After that, there's another practice quiz to check out to make sure all of this has made sense.

### Resources for Debugging Crashes
Check out the following links for more information:

* https://realpython.com/python-concurrency/

* https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32

* https://stackoverflow.com/questions/33047452/definitive-list-of-common-reasons-for-segmentation-faults

* https://sites.google.com/a/case.edu/hpcc/home/important-notes-for-new-users/debugging-segmentation-faults

Readable Python code on GitHub:

* https://github.com/fogleman/Minecraft

* https://github.com/cherrypy/cherrypy

* https://github.com/pallets/flask

* https://github.com/tornadoweb/tornado

* https://github.com/gleitz/howdoi

* https://github.com/bottlepy/bottle/blob/master/bottle.py

* https://github.com/sqlalchemy/sqlalchemy


### Core files vs Log files
Core files contain information about the state of a process in memory when it crashed, including its memory contents, register values, and call stack. This information is used to debug the process and understand why it crashed.

Log files, on the other hand, are text files that record events, errors, and messages generated by applications, operating systems, or other software components during normal operation. Log files are used to monitor the behavior and performance of software, detect issues, and diagnose problems.

In summary, core files provide information about a process after it has crashed, while log files provide information about a process while it is running.

## Handling Bigger Incidents:
### Crashes in Complex Systems
Up to now we've talked about how to diagnose and fix errors that are confined to one computer. That's a common case for computers that are used by a single user. But once we start going into complex systems that involve many different services, we'll need to take a look at the bigger picture and have different computers interact with each other. Say you're in charge of the e-commerce site for your company. The page as seen by the users recently started responding with internal server error to about 20% of all requests. How do you figure out what's going on? You want to apply the same principles that we saw for troubleshooting a problem on one computer, but this time at a larger scale. So you'll want to check the log messages in the servers providing the service, and see if you find any additional information pointing to what's causing the issue. You'll want to find any log specific to the service that's failing, and also look at the general system logs to see if there's a problem affecting the server in general. For this example, let's say you find a bunch of entries in the logs that say, invalid response from server. That's not a great error message. You don't know what the request was or what the response was, but it's at least a clue that whatever's happening is related to some other service in the overall system. We said that this started failing recently, so it might make sense to figure out what changed between what it was working correctly and when it started to fail. Was there a new version of the system deployed? Were there any relevant changes regarding the requests? Let's say this is happening on a Tuesday morning, and the latest release of this service was the previous week. Things were working fine until today, and the requests seemed normal, nothing out of the ordinary. So the service itself is probably okay, but what about the other services involved in the system? Was there a new version of one of the underlying systems, like the database, the authentication service, or some other back-end server like the inventory, billing, or procurement systems? Looking at recent changes, you see that there were a bunch of changes made earlier in the day to the load balancer used between the front-end and the back-end services. Since the only clue you have is that the response from the service was invalid, you're not sure that these changes are at fault, but they sure seem suspicious. Whenever possible, the best strategy is to roll back the changes that you suspect are causing the issue, even if you aren't 100% sure if this is the actual cause. If your infrastructure allows easy rollbacks, try that before doing any further investigation. Why? Because that way, you'll restore the service back to health if it was the cause, or you'll eliminate this change as a possible cause if doing the rollback doesn't help. Whether you do the rollback or not, when coming across unhelpful error messages, it's a good idea to improve them. Instead of the error just saying that the response is invalid, change it to include what the request and the response were, and why the response was invalid. That way, the next time you're trying to debug a similar issue you already have more information to work with. For this example, if the error had included this information you'd have seen that the invalid response was a 404 error. This was caused by having a server added to the pool as part of the inventory system, but the server actually belonged to the procurement system. Now, say a couple of weeks later you see that again, there are a bunch of internal server errors in the same service. It might be tempting to assume that it's the load balancer's fault once again, but by now you know that you should always look at the logs first and see what you find. There's no reason why the error should be the same this time. When looking at the logs you may notice, for example, that only one of the front-end servers is actually affected by the problem. All the other machines are serving their content successfully. In a case like this, you'd start by first removing the machine from the pool of servers that can provide this service. That way, you avoid users getting any more errors. Well, you can investigate what's going on with the broken machine. As you've probably realized by now, when dealing with complex systems like these having good logs is essential to understanding what's going on. On top of that, you'll want to have good monitoring of what the service is doing and use version control for all changes so that you can quickly check what's changed and roll back when needed. It's also important that you can very quickly deploy new machines when necessary. This could be achieved by either keeping standby servers, in case you need to use them, or by having a tested pipeline that allows you to deploy new servers on demand.

A lot of companies today have automated processes for deploying services to virtual machines running in the cloud. This can take a bit of time to set up, but once you've done that you can very easily increase or reduce the amount of servers you're using. This can help a lot when investigating and solving problems. But one thing to take into account when the servers are running as virtual machines, especially if they're running in the cloud, is that there might be external limits apply to these services. Resources, like the available CPU time, RAM, or network bandwidth, might be artificially capped. And not only that, the use of certain external services can also be limited, like how many database connections you can have at the same time or how much data you can store. If these limits are causing problems with your application, you might need to rethink how you use your resources.

We've covered a bunch of techniques that you can use when facing a problem in a complex system. Looking at the available logs, figuring out what changed since the system was last working, rolling back to a previous state, removing faulty servers from the pool, or deploying new servers on demand. Up next, we'll explore a different part of dealing with bigger incidents, communication and documentation.

### Communication and Documentation During Incidents

Until now, we've discussed how we can troubleshoot computers or systems with a specific issue. We've covered how we can get enough information so we can identify the root cause, and then apply the necessary remediation. There's another aspect to all of this. What is related to how we handle the communication with those affected by the issue and how we distribute tasks when addressing large issues as a team. Armed with what you've learned so far and your past experience, you might do a great job troubleshooting a problem. But if you drop the ball when it comes to communicating what you're doing, you could end up with a bunch of frustrated users calling you to find out what's going on. If you don't write down what you've tried or how you fix the problem, you risk for getting some important details and wasting a lot of valuable time when you need to revisit an issue. When working on a problem, it's always a good idea to document what you're doing in a bug or ticket. If there's no such system at your company, then use a doc, a text file, or Wiki, or whatever you have access to. Documenting what you do, lets you keep track of what you've tried and what the results were. This might seem unnecessary. But after a whole day of troubleshooting a problem, it's pretty common for us to forget what we've tried or what was the outcome of a specific action. On top of that, having all this info available in some electronic forum lets you easily share all the data you've collected with other team members. If for example, you brought something back which turned out to be unrelated. Having the whole process document it, helps you remember to roll forward again. While you're working on a problem, it's important to communicate clearly with those affected by the issue. They want to know what you figured out about the problem, what the available workarounds are, and when they can expect the next update. If you don't know what the problem is, it's hard to give an estimation of when you'll have it fixed. But you can still provide timely updates about the work you're doing. This kind of regular communication is helpful no matter the size of the incident. But the more people affected, the more you'll want to provide regular updates with clear instructions of what users can do and what they can expect as a solution. That way, they can better plan and organize their time. If access to the Internet is down, you want to let people know if they can expect to fix in one or two hours or if it's going to take the whole day. This info can make a difference between people choosing to discuss issues in person for a couple of hours or deciding to work from home. If the issue is big enough that you're involving more people in finding a solution, you should agree on who's going to work on which tasks. For example, you could have someone working on finding out a temporary workaround, while someone else is in charge of understanding the root cause of the problem and finding the long-term remediation. Or if there are lots of possible causes for the issue, you could divide the causes among the team members and have them work on those in parallel. On top of people looking for the root cause and a solution, you want to have a person in charge of communicating with the people affected. This lets the team avoid forgetting to update the tracking issue or even worse providing contradictory information. This communications lead needs to know what's going on and provide timely updates on the current state and how long until the problem's resolved. They can act as a shield for questions from users letting the rest of the team focus on the actual problem. Similarly, there should be one person in charge of delegating the different tasks to the team members. This person sometimes called the Incident Commander or Incident Controller needs to look at the big picture and decide what's the best use of the available resources. They can make sure that there's no duplication of work among team members and that only one person is modifying the production system at a time. Having multiple people make overlapping changes to the system could lead to confusing results, making the outage even longer. Of course, this division of roles makes the most sense when there's a large incident and there's a big team working on figuring out the solution. If it's only two or three people working on the problem, it's still important to agree who will work on what but you probably don't need to use any special role names to do that. Once the issue has been resolved, it's super-important to sum up the information that was helpful. The most important information that you'll want to include are the root cause, how you diagnose the problem and found that root cause, what you did to fix the issue and what needs to be done to prevent the problem from happening again. Depending on the size of the issue and the number of people affected, this summary could just be the last update to the bug or ticket that you use to keep track of your work, or it could be a full postmortem. What's a postmortem, and how do you write when you ask? Well, that's coming up in our next section.

### Writing Effective Postmortems
In our last section, we talked about the importance of communication and documentation when troubleshooting incidence. We called out that if the issue is big enough, we might want to document what happened in a postmortem. Postmortems are documents that describe details of incidence to help us learn from our mistakes. When writing a postmortem, the goal isn't to blame whoever caused the incident, but to learn from what happened to prevent the same issue from happening again. To do this, we usually document what happened, why it happened, how it was diagnosed, how it was fixed, and finally figure out what we can do to avoid the same event happening in the future. Remember the main goal is to learn from our mistakes. Writing a postmortem isn't about getting someone fired but about making sure that next time we do better. Writing postmortems after dealing with incidence is important because it helps us avoid dealing with them again or at least learn how to deal with the next incident better. While Postmortems are super useful with large incidence, you don't need to wait until something huge happens to write your first postmortem. You can practice riding them for any kind of event where there's something to be learned no matter how small. That way, when you need to write a postmortem after a big incident, you know how to concentrate on the things that matter the most. What you can learn from the problem and how you can prevent it in the future. So what should you write in a postmortem? The exact structure might vary depending on preference and the type of incident that you're dealing with. In general, you'll want to include the details of what caused the issue, what the impact of the issue was, how it got diagnosed, the short-term remediation you applied, and the long-term remediation you recommend. If the document is long and you're going to share it with a lot of people, you want to include a summary that highlights the root cause, the impact, and what needs to be done to prevent the issue from happening again. It's useful to include what went well in postmortems too. When working on a problem, we might realize that it would have been much worse if we didn't have certain tools or systems available. For example, we might say that we were able to solve the problem quickly by doing a roll back to the previous version or that we caught the issue before users even noticed it because we had good monitoring and alerting. Noting the things that went well helps us show that our systems are effective and justifies keeping those systems running. Writing a postmortem can sometimes help you understand the services that you're working with much better. Earlier this year, a service I worked on had a large outage and I needed to provide information on what happened. To do this, I needed to parse through hundreds of gigabytes of archive logged data to show that certain data had never been received by the service. Doing this, I realized that I needed to improve the data logged by our tools to give better information and have better reporting. You can even practice writing postmortems outside of the IT context. Like, if you bake cookies and they don't turn out as great as you wanted them to, document what you did, what went wrong, what went right, and how you can improve the results in the future. You can do this with any hobby that you have. Maybe photography, 3D printing or brewing your own beer. You don't always need to write the whole thing down. Sometimes a mental note is enough, like if you bike to work and realize wearing your backpack hurts your shoulders, make a mental note to add a basket to your bike. So you can put your backpack there next time, or if on your last trip it was colder than expected and you forgot to bring a jacket, make a mental note that next time you should check the weather before you leave. Once again, remember that the most important part of the postmortem is what we can learn for the future. So if instead of writing a whole document, you're creating a one paragraph summary of the incident. Remember to focus that paragraph on what you can do better, not on whatever mistake caused the incident.

## Module 3 Review:
### Module 3 Wrap Up: Crashing Programs
Congratulations on making it all the way here. You've learned a lot about all kinds of crashes, errors, and incidents over the past videos. We've covered examples of what you can do to work around a problem and you don't have access to the code. We've looked at ways to solve the issues when you do have access to the code, and checked out how to deal with larger incidents that involve complex systems and large teams of people. Learning about the different ways computers and software can fail can seem scary at first. But remember that all of these tools help us get better at coming up with solutions. One of the things I love most about IT is that there are so many different ways to accomplish any task. So if you get stuck, you can always try a new angle. There's nothing like the feeling of solving a tricky problem. Throughout our examples, we've been applying the same techniques that we learned the beginning of the course. We gathered information until we understood the problem. We found the root cause and then worked on the short-term and the long-term remediation. By now, you have a better idea of what you can do when an application crashes unexpectedly, how to use elimination to figure out what's wrong, and what kind of solutions you can apply depending on the failure. Coming up, we've got some problems for you to solve. One where a program is crashing and you can't change the code, and when were you can change the code. This might sound tricky. But remember you can always review the available material to help you figure out what's going on. 
